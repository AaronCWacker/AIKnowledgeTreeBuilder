# Query: Biology Core Rules and Future Exceptions

## AI Response
### üîé Biology Core Rules and Future Exceptions



Biology is a science that is constantly evolving. As such, the rules for biology in the game are subject to change as new discoveries are made.

The following rules are the current rules for biology in the game.

1. All living things are made up of cells.
2. Cells are the basic unit of life.
3. Cells are surrounded by a cell membrane that controls what enters and leaves the cell.
4. Cells contain DNA, which is the genetic material that determines the characteristics of an organism.
5. DNA is made up of two strands that twist around each other to form a double helix.
6. DNA contains the instructions for making proteins, which are the building blocks of cells.
7. Proteins are made up of amino acids.
8. There are 20 different amino acids that can be used to make proteins.
9. Proteins can be classified as either structural or functional.
10. Structural proteins provide support and shape to cells and tissues.
11. Functional proteins carry out specific tasks in cells, such as catalyzing chemical reactions.
12. Cells can be classified as either prokaryotic or eukaryotic.
13. Prokaryotic cells are simpler and smaller than eukaryotic cells.
14. Prokaryotic cells do not have a nucleus or other membrane-bound organelles.
15. Eukaryotic cells are more complex and larger than prokaryotic cells.
16. Eukaryotic cells have a nucleus and other membrane-bound organelles.
17. Cells can reproduce by mitosis or meiosis.
18. Mitosis is the process of cell division that results in two identical daughter cells.
19. Meiosis is the process of cell division that results in four non-identical daughter cells.
20. Meiosis is used for sexual reproduction.
21. Sexual reproduction involves the fusion of two gametes, or sex cells, to form a zygote.
22. Gametes are produced by meiosis.
23. There are two types of gametes: sperm and eggs.
24. Sperm are produced by males and eggs are produced by females.
25
# ü©∫üîç Search Results
### 19 May 2022 | [Reinforcement Learning with Brain-Inspired Modulation can Improve  Adaptation to Environmental Changes](https://arxiv.org/abs/2205.09729) | [‚¨áÔ∏è](https://arxiv.org/pdf/2205.09729)
*Eric Chalmers and Artur Luczak* 

  Developments in reinforcement learning (RL) have allowed algorithms to
achieve impressive performance in highly complex, but largely static problems.
In contrast, biological learning seems to value efficiency of adaptation to a
constantly-changing world. Here we build on a recently-proposed neuronal
learning rule that assumes each neuron can optimize its energy balance by
predicting its own future activity. That assumption leads to a neuronal
learning rule that uses presynaptic input to modulate prediction error. We
argue that an analogous RL rule would use action probability to modulate reward
prediction error. This modulation makes the agent more sensitive to negative
experiences, and more careful in forming preferences. We embed the proposed
rule in both tabular and deep-Q-network RL algorithms, and find that it
outperforms conventional algorithms in simple, but highly-dynamic tasks. We
suggest that the new rule encapsulates a core principle of biological
intelligence; an important component for allowing algorithms to adapt to change
in a human-like way.

---------------

### 30 Jan 2015 | [Text mixing shapes the anatomy of rank-frequency distributions: A modern  Zipfian mechanics for natural language](https://arxiv.org/abs/1409.3870) | [‚¨áÔ∏è](https://arxiv.org/pdf/1409.3870)
*Jake Ryland Williams, James P. Bagrow, Christopher M. Danforth, and  Peter Sheridan Dodds* 

  Natural languages are full of rules and exceptions. One of the most famous
quantitative rules is Zipf's law which states that the frequency of occurrence
of a word is approximately inversely proportional to its rank. Though this
`law' of ranks has been found to hold across disparate texts and forms of data,
analyses of increasingly large corpora over the last 15 years have revealed the
existence of two scaling regimes. These regimes have thus far been explained by
a hypothesis suggesting a separability of languages into core and non-core
lexica. Here, we present and defend an alternative hypothesis, that the two
scaling regimes result from the act of aggregating texts. We observe that text
mixing leads to an effective decay of word introduction, which we show provides
accurate predictions of the location and severity of breaks in scaling. Upon
examining large corpora from 10 languages in the Project Gutenberg eBooks
collection (eBooks), we find emphatic empirical support for the universality of
our claim.

---------------

### 31 Oct 2023 | [A Neurodiversity-Inspired Solver for the Abstraction \& Reasoning Corpus  (ARC) Using Visual Imagery and Program Synthesis](https://arxiv.org/abs/2302.09425) | [‚¨áÔ∏è](https://arxiv.org/pdf/2302.09425)
*James Ainooson, Deepayan Sanyal, Joel P. Michelson, Yuan Yang,  Maithilee Kunda* 

  Core knowledge about physical objects -- e.g., their permanency, spatial
transformations, and interactions -- is one of the most fundamental building
blocks of biological intelligence across humans and non-human animals. While AI
techniques in certain domains (e.g. vision, NLP) have advanced dramatically in
recent years, no current AI systems can yet match human abilities in flexibly
applying core knowledge to solve novel tasks. We propose a new AI approach to
core knowledge that combines 1) visual representations of core knowledge
inspired by human mental imagery abilities, especially as observed in studies
of neurodivergent individuals; with 2) tree-search-based program synthesis for
flexibly combining core knowledge to form new reasoning strategies on the fly.
We demonstrate our system's performance on the very difficult Abstraction \&
Reasoning Corpus (ARC) challenge, and we share experimental results from
publicly available ARC items as well as from our 4th-place finish on the
private test set during the 2022 global ARCathon challenge.

---------------

### 11 Oct 2023 | [Linguistic laws in biology](https://arxiv.org/abs/2310.07387) | [‚¨áÔ∏è](https://arxiv.org/pdf/2310.07387)
*Stuart Semple, Ramon Ferrer-i-Cancho and Morgan L. Gustison* 

  Linguistic laws, the common statistical patterns of human language, have been
investigated by quantitative linguists for nearly a century. Recently,
biologists from a range of disciplines have started to explore the prevalence
of these laws beyond language, finding patterns consistent with linguistic laws
across multiple levels of biological organisation, from molecular (genomes,
genes, and proteins) to organismal (animal behaviour) to ecological
(populations and ecosystems). We propose a new conceptual framework for the
study of linguistic laws in biology, comprising and integrating distinct levels
of analysis, from description to prediction to theory building. Adopting this
framework will provide critical new insights into the fundamental rules of
organisation underpinning natural systems, unifying linguistic laws and core
theory in biology.

---------------

### 22 Jun 2022 | [Efficient visual object representation using a biologically plausible  spike-latency code and winner-take-all inhibition](https://arxiv.org/abs/2205.10338) | [‚¨áÔ∏è](https://arxiv.org/pdf/2205.10338)
*Melani Sanchez-Garcia, Tushar Chauhan, Benoit R. Cottereau, Michael  Beyeler* 

  Deep neural networks have surpassed human performance in key visual
challenges such as object recognition, but require a large amount of energy,
computation, and memory. In contrast, spiking neural networks (SNNs) have the
potential to improve both the efficiency and biological plausibility of object
recognition systems. Here we present a SNN model that uses spike-latency coding
and winner-take-all inhibition (WTA-I) to efficiently represent visual stimuli
from the Fashion MNIST dataset. Stimuli were preprocessed with center-surround
receptive fields and then fed to a layer of spiking neurons whose synaptic
weights were updated using spike-timing-dependent-plasticity (STDP). We
investigate how the quality of the represented objects changes under different
WTA-I schemes and demonstrate that a network of 150 spiking neurons can
efficiently represent objects with as little as 40 spikes. Studying how core
object recognition may be implemented using biologically plausible learning
rules in SNNs may not only further our understanding of the brain, but also
lead to novel and efficient artificial vision systems.

---------------

### 02 Sep 2016 | [Sieve-based Coreference Resolution in the Biomedical Domain](https://arxiv.org/abs/1603.03758) | [‚¨áÔ∏è](https://arxiv.org/pdf/1603.03758)
*Dane Bell and Gus Hahn-Powell and Marco A. Valenzuela-Esc\'arcega and  Mihai Surdeanu* 

  We describe challenges and advantages unique to coreference resolution in the
biomedical domain, and a sieve-based architecture that leverages domain
knowledge for both entity and event coreference resolution. Domain-general
coreference resolution algorithms perform poorly on biomedical documents,
because the cues they rely on such as gender are largely absent in this domain,
and because they do not encode domain-specific knowledge such as the number and
type of participants required in chemical reactions. Moreover, it is difficult
to directly encode this knowledge into most coreference resolution algorithms
because they are not rule-based. Our rule-based architecture uses sequentially
applied hand-designed "sieves", with the output of each sieve informing and
constraining subsequent sieves. This architecture provides a 3.2% increase in
throughput to our Reach event extraction system with precision parallel to that
of the stricter system that relies solely on syntactic patterns for extraction.

---------------

### 07 Feb 2023 | [Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid  Learning in RNNs](https://arxiv.org/abs/2302.03235) | [‚¨áÔ∏è](https://arxiv.org/pdf/2302.03235)
*Yu Duan, Zhongfan Jia, Qian Li, Yi Zhong, Kaisheng Ma* 

  Rapidly learning from ongoing experiences and remembering past events with a
flexible memory system are two core capacities of biological intelligence.
While the underlying neural mechanisms are not fully understood, various
evidence supports that synaptic plasticity plays a critical role in memory
formation and fast learning. Inspired by these results, we equip Recurrent
Neural Networks (RNNs) with plasticity rules to enable them to adapt their
parameters according to ongoing experiences. In addition to the traditional
local Hebbian plasticity, we propose a global, gradient-based plasticity rule,
which allows the model to evolve towards its self-determined target. Our models
show promising results on sequential and associative memory tasks, illustrating
their ability to robustly form and retain memories. In the meantime, these
models can cope with many challenging few-shot learning problems. Comparing
different plasticity rules under the same framework shows that Hebbian
plasticity is well-suited for several memory and associative learning tasks;
however, it is outperformed by gradient-based plasticity on few-shot regression
tasks which require the model to infer the underlying mapping. Code is
available at https://github.com/yuvenduan/PlasticRNNs.

---------------

### 09 Jul 2022 | [Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises  and Challenges](https://arxiv.org/abs/2207.04295) | [‚¨áÔ∏è](https://arxiv.org/pdf/2207.04295)
*Guang Yang, Arvind Rao, Christine Fernandez-Maloigne, Vince Calhoun,  Gloria Menegaz* 

  Artificial intelligence has become pervasive across disciplines and fields,
and biomedical image and signal processing is no exception. The growing and
widespread interest on the topic has triggered a vast research activity that is
reflected in an exponential research effort. Through study of massive and
diverse biomedical data, machine and deep learning models have revolutionized
various tasks such as modeling, segmentation, registration, classification and
synthesis, outperforming traditional techniques. However, the difficulty in
translating the results into biologically/clinically interpretable information
is preventing their full exploitation in the field. Explainable AI (XAI)
attempts to fill this translational gap by providing means to make the models
interpretable and providing explanations. Different solutions have been
proposed so far and are gaining increasing interest from the community. This
paper aims at providing an overview on XAI in biomedical data processing and
points to an upcoming Special Issue on Deep Learning in Biomedical Image and
Signal Processing of the IEEE Signal Processing Magazine that is going to
appear in March 2022.

---------------

### 05 Aug 2016 | [Self-Organising Maps in Computer Security](https://arxiv.org/abs/1608.01668) | [‚¨áÔ∏è](https://arxiv.org/pdf/1608.01668)
*Jan Feyereisl and Uwe Aickelin* 

  Some argue that biologically inspired algorithms are the future of solving
difficult problems in computer science. Others strongly believe that the future
lies in the exploration of mathematical foundations of problems at hand. The
field of computer security tends to accept the latter view as a more
appropriate approach due to its more workable validation and verification
possibilities. The lack of rigorous scientific practices prevalent in
biologically inspired security research does not aid in presenting bio-inspired
security approaches as a viable way of dealing with complex security problems.
This chapter introduces a biologically inspired algorithm, called the Self
Organising Map (SOM), that was developed by Teuvo Kohonen in 1981. Since the
algorithm's inception it has been scrutinised by the scientific community and
analysed in more than 4000 research papers, many of which dealt with various
computer security issues, from anomaly detection, analysis of executables all
the way to wireless network monitoring. In this chapter a review of security
related SOM research undertaken in the past is presented and analysed. The
algorithm's biological analogies are detailed and the author's view on the
future possibilities of this successful bio-inspired approach are given. The
SOM algorithm's close relation to a number of vital functions of the human
brain and the emergence of multi-core computer architectures are the two main
reasons behind our assumption that the future of the SOM algorithm and its
variations is promising, notably in the field of computer security.

---------------

### 09 Feb 2020 | [Medical Image Registration Using Deep Neural Networks: A Comprehensive  Review](https://arxiv.org/abs/2002.03401) | [‚¨áÔ∏è](https://arxiv.org/pdf/2002.03401)
*Hamid Reza Boveiri, Raouf Khayami, Reza Javidan, Ali Reza MehdiZadeh* 

  Image-guided interventions are saving the lives of a large number of patients
where the image registration problem should indeed be considered as the most
complex and complicated issue to be tackled. On the other hand, the recently
huge progress in the field of machine learning made by the possibility of
implementing deep neural networks on the contemporary many-core GPUs opened up
a promising window to challenge with many medical applications, where the
registration is not an exception. In this paper, a comprehensive review on the
state-of-the-art literature known as medical image registration using deep
neural networks is presented. The review is systematic and encompasses all the
related works previously published in the field. Key concepts, statistical
analysis from different points of view, confiding challenges, novelties and
main contributions, key-enabling techniques, future directions and prospective
trends all are discussed and surveyed in details in this comprehensive review.
This review allows a deep understanding and insight for the readers active in
the field who are investigating the state-of-the-art and seeking to contribute
the future literature.

---------------

### 12 May 2021 | [The Greedy and Recursive Search for Morphological Productivity](https://arxiv.org/abs/2105.05790) | [‚¨áÔ∏è](https://arxiv.org/pdf/2105.05790)
*Caleb Belth, Sarah Payne, Deniz Beser, Jordan Kodner, Charles Yang* 

  As children acquire the knowledge of their language's morphology, they
invariably discover the productive processes that can generalize to new words.
Morphological learning is made challenging by the fact that even fully
productive rules have exceptions, as in the well-known case of English past
tense verbs, which features the -ed rule against the irregular verbs. The
Tolerance Principle is a recent proposal that provides a precise threshold of
exceptions that a productive rule can withstand. Its empirical application so
far, however, requires the researcher to fully specify rules defined over a set
of words. We propose a greedy search model that automatically hypothesizes
rules and evaluates their productivity over a vocabulary. When the search for
broader productivity fails, the model recursively subdivides the vocabulary and
continues the search for productivity over narrower rules. Trained on
psychologically realistic data from child-directed input, our model displays
developmental patterns observed in child morphology acquisition, including the
notoriously complex case of German noun pluralization. It also produces
responses to nonce words that, despite receiving only a fraction of the
training data, are more similar to those of human subjects than current neural
network models' responses are.

---------------

### 28 Mar 2014 | [Predicate Logic as a Modeling Language: Modeling and Solving some  Machine Learning and Data Mining Problems with IDP3](https://arxiv.org/abs/1309.6883) | [‚¨áÔ∏è](https://arxiv.org/pdf/1309.6883)
*Maurice Bruynooghe, Hendrik Blockeel, Bart Bogaerts, Broes De Cat,  Stef De Pooter, Joachim Jansen, Anthony Labarre, Jan Ramon, Marc Denecker and  Sicco Verwer* 

  This paper provides a gentle introduction to problem solving with the IDP3
system. The core of IDP3 is a finite model generator that supports first order
logic enriched with types, inductive definitions, aggregates and partial
functions. It offers its users a modeling language that is a slight extension
of predicate logic and allows them to solve a wide range of search problems.
Apart from a small introductory example, applications are selected from
problems that arose within machine learning and data mining research. These
research areas have recently shown a strong interest in declarative modeling
and constraint solving as opposed to algorithmic approaches. The paper
illustrates that the IDP3 system can be a valuable tool for researchers with
such an interest.
  The first problem is in the domain of stemmatology, a domain of philology
concerned with the relationship between surviving variant versions of text. The
second problem is about a somewhat related problem within biology where
phylogenetic trees are used to represent the evolution of species. The third
and final problem concerns the classical problem of learning a minimal
automaton consistent with a given set of strings. For this last problem, we
show that the performance of our solution comes very close to that of a
state-of-the art solution. For each of these applications, we analyze the
problem, illustrate the development of a logic-based model and explore how
alternatives can affect the performance.

---------------

### 19 Feb 2024 | [Major TOM: Expandable Datasets for Earth Observation](https://arxiv.org/abs/2402.12095) | [‚¨áÔ∏è](https://arxiv.org/pdf/2402.12095)
*Alistair Francis and Mikolaj Czerkawski* 

  Deep learning models are increasingly data-hungry, requiring significant
resources to collect and compile the datasets needed to train them, with Earth
Observation (EO) models being no exception. However, the landscape of datasets
in EO is relatively atomised, with interoperability made difficult by diverse
formats and data structures. If ever larger datasets are to be built, and
duplication of effort minimised, then a shared framework that allows users to
combine and access multiple datasets is needed. Here, Major TOM (Terrestrial
Observation Metaset) is proposed as this extensible framework. Primarily, it
consists of a geographical indexing system based on a set of grid points and a
metadata structure that allows multiple datasets with different sources to be
merged. Besides the specification of Major TOM as a framework, this work also
presents a large, open-access dataset, MajorTOM-Core, which covers the vast
majority of the Earth's land surface. This dataset provides the community with
both an immediately useful resource, as well as acting as a template for future
additions to the Major TOM ecosystem. Access: https://huggingface.co/Major-TOM

---------------

### 13 Oct 2022 | [ezCoref: Towards Unifying Annotation Guidelines for Coreference  Resolution](https://arxiv.org/abs/2210.07188) | [‚¨áÔ∏è](https://arxiv.org/pdf/2210.07188)
*Ankita Gupta, Marzena Karpinska, Wenlong Zhao, Kalpesh Krishna, Jack  Merullo, Luke Yeh, Mohit Iyyer, Brendan O'Connor* 

  Large-scale, high-quality corpora are critical for advancing research in
coreference resolution. However, existing datasets vary in their definition of
coreferences and have been collected via complex and lengthy guidelines that
are curated for linguistic experts. These concerns have sparked a growing
interest among researchers to curate a unified set of guidelines suitable for
annotators with various backgrounds. In this work, we develop a
crowdsourcing-friendly coreference annotation methodology, ezCoref, consisting
of an annotation tool and an interactive tutorial. We use ezCoref to
re-annotate 240 passages from seven existing English coreference datasets
(spanning fiction, news, and multiple other domains) while teaching annotators
only cases that are treated similarly across these datasets. Surprisingly, we
find that reasonable quality annotations were already achievable (>90%
agreement between the crowd and expert annotations) even without extensive
training. On carefully analyzing the remaining disagreements, we identify the
presence of linguistic cases that our annotators unanimously agree upon but
lack unified treatments (e.g., generic pronouns, appositives) in existing
datasets. We propose the research community should revisit these phenomena when
curating future unified annotation guidelines.

---------------

### 31 May 2021 | [Coreference Resolution without Span Representations](https://arxiv.org/abs/2101.00434) | [‚¨áÔ∏è](https://arxiv.org/pdf/2101.00434)
*Yuval Kirstain, Ori Ram, Omer Levy* 

  The introduction of pretrained language models has reduced many complex
task-specific NLP models to simple lightweight layers. An exception to this
trend is coreference resolution, where a sophisticated task-specific model is
appended to a pretrained transformer encoder. While highly effective, the model
has a very large memory footprint -- primarily due to dynamically-constructed
span and span-pair representations -- which hinders the processing of complete
documents and the ability to train on multiple instances in a single batch. We
introduce a lightweight end-to-end coreference model that removes the
dependency on span representations, handcrafted features, and heuristics. Our
model performs competitively with the current standard model, while being
simpler and more efficient.

---------------

### 16 Oct 2022 | [Distinguishing Learning Rules with Brain Machine Interfaces](https://arxiv.org/abs/2206.13448) | [‚¨áÔ∏è](https://arxiv.org/pdf/2206.13448)
*Jacob P. Portes, Christian Schmid, James M. Murray* 

  Despite extensive theoretical work on biologically plausible learning rules,
clear evidence about whether and how such rules are implemented in the brain
has been difficult to obtain. We consider biologically plausible supervised-
and reinforcement-learning rules and ask whether changes in network activity
during learning can be used to determine which learning rule is being used.
Supervised learning requires a credit-assignment model estimating the mapping
from neural activity to behavior, and, in a biological organism, this model
will inevitably be an imperfect approximation of the ideal mapping, leading to
a bias in the direction of the weight updates relative to the true gradient.
Reinforcement learning, on the other hand, requires no credit-assignment model
and tends to make weight updates following the true gradient direction. We
derive a metric to distinguish between learning rules by observing changes in
the network activity during learning, given that the mapping from brain to
behavior is known by the experimenter. Because brain-machine interface (BMI)
experiments allow for precise knowledge of this mapping, we model a
cursor-control BMI task using recurrent neural networks, showing that learning
rules can be distinguished in simulated experiments using only observations
that a neuroscience experimenter would plausibly have access to.

---------------

### 17 Jun 2020 | [ODE-Inspired Analysis for the Biological Version of Oja's Rule in  Solving Streaming PCA](https://arxiv.org/abs/1911.02363) | [‚¨áÔ∏è](https://arxiv.org/pdf/1911.02363)
*Chi-Ning Chou, Mien Brabeeba Wang* 

  Oja's rule [Oja, Journal of mathematical biology 1982] is a well-known
biologically-plausible algorithm using a Hebbian-type synaptic update rule to
solve streaming principal component analysis (PCA). Computational
neuroscientists have known that this biological version of Oja's rule converges
to the top eigenvector of the covariance matrix of the input in the limit.
However, prior to this work, it was open to prove any convergence rate
guarantee.
  In this work, we give the first convergence rate analysis for the biological
version of Oja's rule in solving streaming PCA. Moreover, our convergence rate
matches the information theoretical lower bound up to logarithmic factors and
outperforms the state-of-the-art upper bound for streaming PCA. Furthermore, we
develop a novel framework inspired by ordinary differential equations (ODE) to
analyze general stochastic dynamics. The framework abandons the traditional
step-by-step analysis and instead analyzes a stochastic dynamic in one-shot by
giving a closed-form solution to the entire dynamic. The one-shot framework
allows us to apply stopping time and martingale techniques to have a flexible
and precise control on the dynamic. We believe that this general framework is
powerful and should lead to effective yet simple analysis for a large class of
problems with stochastic dynamics.

---------------

### 20 Dec 2022 | [Hybrid Rule-Neural Coreference Resolution System based on Actor-Critic  Learning](https://arxiv.org/abs/2212.10087) | [‚¨áÔ∏è](https://arxiv.org/pdf/2212.10087)
*Yu Wang and Hongxia Jin* 

  A coreference resolution system is to cluster all mentions that refer to the
same entity in a given context. All coreference resolution systems need to
tackle two main tasks: one task is to detect all of the potential mentions, and
the other is to learn the linking of an antecedent for each possible mention.
In this paper, we propose a hybrid rule-neural coreference resolution system
based on actor-critic learning, such that it can achieve better coreference
performance by leveraging the advantages from both the heuristic rules and a
neural conference model. This end-to-end system can also perform both mention
detection and resolution by leveraging a joint training algorithm. We
experiment on the BERT model to generate input span representations. Our model
with the BERT span representation achieves the state-of-the-art performance
among the models on the CoNLL-2012 Shared Task English Test Set.

---------------

### 06 Nov 2007 | [Addendum to Research MMMCV; A Man/Microbio/Megabio/Computer Vision](https://arxiv.org/abs/0711.0784) | [‚¨áÔ∏è](https://arxiv.org/pdf/0711.0784)
*Philip B. Alipour* 

  In October 2007, a Research Proposal for the University of Sydney, Australia,
the author suggested that biovie-physical phenomenon as `electrodynamic
dependant biological vision', is governed by relativistic quantum laws and
biovision. The phenomenon on the basis of `biovielectroluminescence', satisfies
man/microbio/megabio/computer vision (MMMCV), as a robust candidate for
physical and visual sciences. The general aim of this addendum is to present a
refined text of Sections 1-3 of that proposal and highlighting the contents of
its Appendix in form of a `Mechanisms' Section. We then briefly remind in an
article aimed for December 2007, by appending two more equations into Section
3, a theoretical II-time scenario as a time model well-proposed for the
phenomenon. The time model within the core of the proposal, plays a significant
role in emphasizing the principle points on Objectives no. 1-8, Sub-hypothesis
3.1.2, mentioned in Article [arXiv:0710.0410]. It also expresses the time
concept in terms of causing quantized energy f(|E|) of time |t|, emit in regard
to shortening the probability of particle loci as predictable patterns of
particle's un-occurred motion, a solution to Heisenberg's uncertainty principle
(HUP) into a simplistic manner. We conclude that, practical frames via a time
algorithm to this model, fixates such predictable patterns of motion of scenery
bodies onto recordable observation points of a MMMCV system. It even
suppresses/predicts superposition phenomena coming from a human subject and/or
other bio-subjects for any decision making event, e.g., brainwave quantum
patterns based on vision. Maintaining the existential probability of Riemann
surfaces of II-time scenarios in the context of biovielectroluminescence, makes
motion-prediction a possibility.

---------------

### 29 Nov 2022 | [Sequence learning in a spiking neuronal network with memristive synapses](https://arxiv.org/abs/2211.16592) | [‚¨áÔ∏è](https://arxiv.org/pdf/2211.16592)
*Younes Bouhadjar, Sebastian Siegel, Tom Tetzlaff, Markus Diesmann,  Rainer Waser, Dirk J. Wouters* 

  Brain-inspired computing proposes a set of algorithmic principles that hold
promise for advancing artificial intelligence. They endow systems with self
learning capabilities, efficient energy usage, and high storage capacity. A
core concept that lies at the heart of brain computation is sequence learning
and prediction. This form of computation is essential for almost all our daily
tasks such as movement generation, perception, and language. Understanding how
the brain performs such a computation is not only important to advance
neuroscience but also to pave the way to new technological brain-inspired
applications. A previously developed spiking neural network implementation of
sequence prediction and recall learns complex, high-order sequences in an
unsupervised manner by local, biologically inspired plasticity rules. An
emerging type of hardware that holds promise for efficiently running this type
of algorithm is neuromorphic hardware. It emulates the way the brain processes
information and maps neurons and synapses directly into a physical substrate.
Memristive devices have been identified as potential synaptic elements in
neuromorphic hardware. In particular, redox-induced resistive random access
memories (ReRAM) devices stand out at many aspects. They permit scalability,
are energy efficient and fast, and can implement biological plasticity rules.
In this work, we study the feasibility of using ReRAM devices as a replacement
of the biological synapses in the sequence learning model. We implement and
simulate the model including the ReRAM plasticity using the neural simulator
NEST. We investigate the effect of different device properties on the
performance characteristics of the sequence learning model, and demonstrate
resilience with respect to different on-off ratios, conductance resolutions,
device variability, and synaptic failure.

---------------
**Date:** 19 May 2022

**Title:** Reinforcement Learning with Brain-Inspired Modulation can Improve  Adaptation to Environmental Changes

**Abstract Link:** [https://arxiv.org/abs/2205.09729](https://arxiv.org/abs/2205.09729)

**PDF Link:** [https://arxiv.org/pdf/2205.09729](https://arxiv.org/pdf/2205.09729)

---

**Date:** 30 Jan 2015

**Title:** Text mixing shapes the anatomy of rank-frequency distributions: A modern  Zipfian mechanics for natural language

**Abstract Link:** [https://arxiv.org/abs/1409.3870](https://arxiv.org/abs/1409.3870)

**PDF Link:** [https://arxiv.org/pdf/1409.3870](https://arxiv.org/pdf/1409.3870)

---

**Date:** 31 Oct 2023

**Title:** A Neurodiversity-Inspired Solver for the Abstraction \& Reasoning Corpus  (ARC) Using Visual Imagery and Program Synthesis

**Abstract Link:** [https://arxiv.org/abs/2302.09425](https://arxiv.org/abs/2302.09425)

**PDF Link:** [https://arxiv.org/pdf/2302.09425](https://arxiv.org/pdf/2302.09425)

---

**Date:** 11 Oct 2023

**Title:** Linguistic laws in biology

**Abstract Link:** [https://arxiv.org/abs/2310.07387](https://arxiv.org/abs/2310.07387)

**PDF Link:** [https://arxiv.org/pdf/2310.07387](https://arxiv.org/pdf/2310.07387)

---

**Date:** 22 Jun 2022

**Title:** Efficient visual object representation using a biologically plausible  spike-latency code and winner-take-all inhibition

**Abstract Link:** [https://arxiv.org/abs/2205.10338](https://arxiv.org/abs/2205.10338)

**PDF Link:** [https://arxiv.org/pdf/2205.10338](https://arxiv.org/pdf/2205.10338)

---

**Date:** 02 Sep 2016

**Title:** Sieve-based Coreference Resolution in the Biomedical Domain

**Abstract Link:** [https://arxiv.org/abs/1603.03758](https://arxiv.org/abs/1603.03758)

**PDF Link:** [https://arxiv.org/pdf/1603.03758](https://arxiv.org/pdf/1603.03758)

---

**Date:** 07 Feb 2023

**Title:** Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid  Learning in RNNs

**Abstract Link:** [https://arxiv.org/abs/2302.03235](https://arxiv.org/abs/2302.03235)

**PDF Link:** [https://arxiv.org/pdf/2302.03235](https://arxiv.org/pdf/2302.03235)

---

**Date:** 09 Jul 2022

**Title:** Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises  and Challenges

**Abstract Link:** [https://arxiv.org/abs/2207.04295](https://arxiv.org/abs/2207.04295)

**PDF Link:** [https://arxiv.org/pdf/2207.04295](https://arxiv.org/pdf/2207.04295)

---

**Date:** 05 Aug 2016

**Title:** Self-Organising Maps in Computer Security

**Abstract Link:** [https://arxiv.org/abs/1608.01668](https://arxiv.org/abs/1608.01668)

**PDF Link:** [https://arxiv.org/pdf/1608.01668](https://arxiv.org/pdf/1608.01668)

---

**Date:** 09 Feb 2020

**Title:** Medical Image Registration Using Deep Neural Networks: A Comprehensive  Review

**Abstract Link:** [https://arxiv.org/abs/2002.03401](https://arxiv.org/abs/2002.03401)

**PDF Link:** [https://arxiv.org/pdf/2002.03401](https://arxiv.org/pdf/2002.03401)

---

**Date:** 12 May 2021

**Title:** The Greedy and Recursive Search for Morphological Productivity

**Abstract Link:** [https://arxiv.org/abs/2105.05790](https://arxiv.org/abs/2105.05790)

**PDF Link:** [https://arxiv.org/pdf/2105.05790](https://arxiv.org/pdf/2105.05790)

---

**Date:** 28 Mar 2014

**Title:** Predicate Logic as a Modeling Language: Modeling and Solving some  Machine Learning and Data Mining Problems with IDP3

**Abstract Link:** [https://arxiv.org/abs/1309.6883](https://arxiv.org/abs/1309.6883)

**PDF Link:** [https://arxiv.org/pdf/1309.6883](https://arxiv.org/pdf/1309.6883)

---

**Date:** 19 Feb 2024

**Title:** Major TOM: Expandable Datasets for Earth Observation

**Abstract Link:** [https://arxiv.org/abs/2402.12095](https://arxiv.org/abs/2402.12095)

**PDF Link:** [https://arxiv.org/pdf/2402.12095](https://arxiv.org/pdf/2402.12095)

---

**Date:** 13 Oct 2022

**Title:** ezCoref: Towards Unifying Annotation Guidelines for Coreference  Resolution

**Abstract Link:** [https://arxiv.org/abs/2210.07188](https://arxiv.org/abs/2210.07188)

**PDF Link:** [https://arxiv.org/pdf/2210.07188](https://arxiv.org/pdf/2210.07188)

---

**Date:** 31 May 2021

**Title:** Coreference Resolution without Span Representations

**Abstract Link:** [https://arxiv.org/abs/2101.00434](https://arxiv.org/abs/2101.00434)

**PDF Link:** [https://arxiv.org/pdf/2101.00434](https://arxiv.org/pdf/2101.00434)

---

**Date:** 16 Oct 2022

**Title:** Distinguishing Learning Rules with Brain Machine Interfaces

**Abstract Link:** [https://arxiv.org/abs/2206.13448](https://arxiv.org/abs/2206.13448)

**PDF Link:** [https://arxiv.org/pdf/2206.13448](https://arxiv.org/pdf/2206.13448)

---

**Date:** 17 Jun 2020

**Title:** ODE-Inspired Analysis for the Biological Version of Oja's Rule in  Solving Streaming PCA

**Abstract Link:** [https://arxiv.org/abs/1911.02363](https://arxiv.org/abs/1911.02363)

**PDF Link:** [https://arxiv.org/pdf/1911.02363](https://arxiv.org/pdf/1911.02363)

---

**Date:** 20 Dec 2022

**Title:** Hybrid Rule-Neural Coreference Resolution System based on Actor-Critic  Learning

**Abstract Link:** [https://arxiv.org/abs/2212.10087](https://arxiv.org/abs/2212.10087)

**PDF Link:** [https://arxiv.org/pdf/2212.10087](https://arxiv.org/pdf/2212.10087)

---

**Date:** 06 Nov 2007

**Title:** Addendum to Research MMMCV; A Man/Microbio/Megabio/Computer Vision

**Abstract Link:** [https://arxiv.org/abs/0711.0784](https://arxiv.org/abs/0711.0784)

**PDF Link:** [https://arxiv.org/pdf/0711.0784](https://arxiv.org/pdf/0711.0784)

---

**Date:** 29 Nov 2022

**Title:** Sequence learning in a spiking neuronal network with memristive synapses

**Abstract Link:** [https://arxiv.org/abs/2211.16592](https://arxiv.org/abs/2211.16592)

**PDF Link:** [https://arxiv.org/pdf/2211.16592](https://arxiv.org/pdf/2211.16592)

---


